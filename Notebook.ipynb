{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "We’ve talked about how to make predictions. In some form or another, we used deep neural networks learned mappings from data points to labels. This kind of learning is called discriminative learning, as in, we’d like to be able to discriminate between photos cats and photos of dogs. Classifiers and regressors are both examples of discriminative learning. And neural networks trained by backpropagation have upended everything we thought we knew about discriminative learning on large complicated datasets. Classification accuracies on high-res images has gone from useless to human-level (withsome caveats) in just 5-6 years. We’ll spare you another spiel about all the other discriminative tasks where deep neural networks do astoundingly well.\n",
    "\n",
    "But there’s more to machine learning than just solving discriminative tasks. For example, given a largedataset, without any labels, we might want to learn a model that concisely captures the characteristics of this data. Given such a model, we could sample synthetic data points that resemble the distribution ofthe training data. For example, given a large corpus of photographs of faces, we might want to be able togenerate a new photorealistic image that looks like it might plausibly have come from the same dataset.This kind of learning is called `generative modeling`.\n",
    "\n",
    "Until recently, we had no method that could synthesize novel photorealistic images. But the success of deep neural networks for discriminative learning opened up new possibilities. One big trend over the last three years has been the application of discriminative deep nets to overcome challenges in problems that we don’t generally think of as supervised learning problems. The recurrent neural network language models are one example of using a discriminative network (trained to predict the next character) that once trained can actas a generative model.\n",
    "\n",
    "In 2014, a breakthrough paper introduced `Generative adversarial networks (GANs)`, a clever new way to leverage the power of discriminative models to get good generative models. At their heart, GANs rely on the idea that a data generator is good if we cannot tell fake data apart from real data. In statistics, this is calleda two-sample test - a test to answer the question whether datasets $X= {x_1;...;x_n}$ and $X'= {x'_1;...;x'_n}$ were drawn from the same distribution. The main difference between most statistics papers and GANs is that the latter use this idea in a constructive way. In other words, rather than just training a model to say “hey, these two datasets don’t look like they came from the same distribution”, they use the `two-sample test` to provide training signal to a generative model. This allows us to improve the data generator until it generates something that resembles the real data. At the very least, it needs to fool the classifier. And ifour classifier is a state of the art deep neural network.\n",
    "\n",
    "The GANs architecture is illustrated in `Figure 1`. As you can see, there are two pieces to GANs - first off, we need a device (say, a deep network but it really could be anything, such as a game rendering engine) that might potentially be able to generate data that looks just like the real thing. If we are dealing with images, this needs to generate images. If we’re dealing with speech, it needs to generate audio sequences, and soon. We call this the generator network. The second component is the discriminator network. It attempts to distinguish fake and real data from each other. Both networks are in competition with each other. The generator network attempts to fool the discriminator network. At that point, the discriminator network adapts to the new fake data. This information, in turn is used to improve the generator network, and so on.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/gan.svg\"><br>\n",
    "    Figure 1. Generative Adversarial Networks\n",
    "</p>\n",
    "\n",
    "The discriminator is a binary classifier to distinguish if the inputxis real (from real data) or fake (from the generator). Typically, the discriminator outputs a scalar prediction $ o \\in R $ for input $\\mathbf x$, such as using a dense layer with hidden size 1, and then applies sigmoid function to obtain the predicted probability $ D(x) = 1/(1 + e^{-x}) $. Assume the label y for true data is 1 and 0 for fake data. We train the discriminator to minimize the cross entropy loss, i.e $$ \\min - y \\log D(\\mathbf x) - (1-y)\\log(1-D(\\mathbf x)) $$\n",
    "\n",
    "For the generator, it first draws some parameter $ z \\in R^d $ from a source of randomness, e.g. a normal distribution $ \\mathbf z \\sim\\mathcal(0;1) $. We often call z the `latent variable`. It then applies a function to generate $ \\mathbf x′=G(\\mathbf z) $. The goal of the generator is to fool the discriminator to classify $x′$ as true data. In other words, we update the parameters of the generator to maximize the cross entropy loss when y= 0, i.e. $$ \\max - \\log(1-D(\\mathbf x'))$$\n",
    "\n",
    "If the discriminator does a perfect job, then $ D(\\mathbf x')\\approx 1 $ so the above loss near 0, which results the gradients are too small to make a good progress for the discriminator. So commonly we minimize the following loss $$ \\max \\log(D(\\mathbf x')) $$\n",
    "\n",
    "which is just feed $\\mathbf x' $ into the discriminator but giving label $y=1$.\n",
    "\n",
    "Many of the GANs applications are in the context of images. As a demonstration purpose, we're going to content ourselves with fitting a much simpler distribution first. We will illustrate what happens if we use GANs to build the world's most inefficient estimator of parameters for a Gaussian. Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary dependencies\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import d2l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate some “real” data\n",
    "-------------------------------\n",
    "\n",
    "Since this is going to be the world’s lamest example, we simply generate data drawn from a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size=(1000, 2))\n",
    "X = torch.from_numpy(X).float()\n",
    "A = torch.tensor([[ 1. , 2. ],\n",
    "                  [-0.1, 0.5]])\n",
    "b = torch.tensor([1., 2.])\n",
    "data = torch.matmul(X, A) + b\n",
    "\n",
    "\n",
    "class GANDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.dataset = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:100, 0].numpy(), data[:100,  1].numpy())\n",
    "plt.show()\n",
    "print(f'The covariance matrix is {torch.matmul(A.T,A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generator\n",
    "---------------\n",
    "\n",
    "Our generator network will be the simplest network possible - a single layer linear model. This is since we’llbe driving that linear network with a Gaussian data generator. Hence, it literally only needs to learn the parameters to fake things perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(device=None):\n",
    "    net_G = nn.Sequential(\n",
    "        nn.Linear(2, 2)\n",
    "    )\n",
    "    \n",
    "    if device is not None:\n",
    "        net_G.to(device)\n",
    "    \n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discriminator\n",
    "-------------------\n",
    "\n",
    "For the discriminator we will be a bit more discriminating: we will use an MLP with 3 layers to make things a bit more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(device=None):\n",
    "    net_D = nn.Sequential(\n",
    "        nn.Linear(2, 5),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(5, 3),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(3, 1)\n",
    "    )\n",
    "    \n",
    "    if device is not None:\n",
    "        net_D.to(device)\n",
    "    \n",
    "    return net_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "--------------\n",
    "\n",
    "First we define a function to update the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_D(X, Z, net_D, net_G, loss, optimizer_D):\n",
    "    \"\"\"Updates discriminator.\"\"\"\n",
    "    batch_size = X.size(0)\n",
    "    ones = X.new_ones(size=(batch_size, 1))\n",
    "    zeros = X.new_zeros(size=(batch_size, 1))\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer_D.zero_grad()\n",
    "    \n",
    "    real_Y = net_D(X)\n",
    "    fake_X = net_G(Z)\n",
    "    # Don't need to compute gradient for net_G, detach it from\n",
    "    # computing gradients.\n",
    "    fake_Y = net_D(fake_X.detach())\n",
    "    loss_D = (loss(real_Y, ones) + loss(fake_Y, zeros)) / 2\n",
    "    \n",
    "    loss_D.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    return loss_D.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator is updated similarly. Here we reuse the cross-entropy loss but change the label of the fake data from $0$ to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_G(Z, net_D, net_G, loss, optimizer_G):\n",
    "    \"\"\"Updates generator.\"\"\"\n",
    "    batch_size = Z.size(0)\n",
    "    ones = Z.new_ones(size=(batch_size, 1))\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer_G.zero_grad()\n",
    "    \n",
    "    # We could reuse fake_X from update_D to save computation.\n",
    "    fake_X = net_G(Z)\n",
    "    # Recomputing fake_Y is needed since net_D is changed.\n",
    "    fake_Y = net_D(fake_X)\n",
    "    loss_G = loss(fake_Y, ones)\n",
    "    \n",
    "    loss_G.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    return loss_G.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the discriminator and the generator performs a binary logistic regression with the cross-entropy loss. We use Adam to smooth the training process. In each iteration, we first update the discriminator and then the generator. We visualize both losses and generated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G, latent_dim, data):\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer_D = optim.Adam(net_D.parameters(), lr=lr_D)\n",
    "    optimizer_G = optim.Adam(net_G.parameters(), lr=lr_G)\n",
    "    \n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[1, num_epochs], nrows=2, figsize=(5,5),\n",
    "                            legend=['generator', 'discriminator'])\n",
    "    animator.fig.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train one epoch\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(3)  # loss_D, loss_G, num_examples\n",
    "        \n",
    "        for _, X in enumerate(data_iter):\n",
    "            batch_size = X.size(0)\n",
    "            X = X.view(-1, latent_dim)\n",
    "            X = X.to(device)\n",
    "            \n",
    "            # z latent variables\n",
    "            Z = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            Z = torch.from_numpy(Z).float()\n",
    "            Z = Z.view(-1, latent_dim)\n",
    "            Z = Z.to(device)\n",
    "            \n",
    "            metric.add(update_D(X, Z, net_D, net_G, loss, optimizer_D),\n",
    "                       update_G(Z, net_D, net_G, loss, optimizer_G),\n",
    "                       batch_size)\n",
    "        \n",
    "        # Visualize generated examples\n",
    "        Z = np.random.normal(0, 1, size=(100, latent_dim))\n",
    "        Z = torch.from_numpy(Z).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            fake_X = net_G(Z).cpu()\n",
    "            fake_X = fake_X.numpy()\n",
    "        animator.axes[1].cla()\n",
    "        animator.axes[1].scatter(data[:,0], data[:,1])\n",
    "        animator.axes[1].scatter(fake_X[:,0], fake_X[:,1])\n",
    "        animator.axes[1].legend(['real', 'generated'])\n",
    "        \n",
    "        # Show the losses\n",
    "        loss_D, loss_G = metric[0]/metric[2], metric[1]/metric[2]\n",
    "        animator.add(epoch, (loss_D, loss_G))\n",
    "    \n",
    "    print(f'loss_D {loss_D:.3f}, loss_G {loss_G:.3f}, {metric[2]/timer.stop()} examples/sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the hyper-parameters to fit the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_D = 0.05\n",
    "lr_G = 0.005\n",
    "latent_dim = 2\n",
    "num_epochs = 20\n",
    "\n",
    "trainset = GANDataset(data)\n",
    "trainloader = DataLoader(trainset, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net_G = get_generator(device)\n",
    "net_D = get_discriminator(device)\n",
    "train(net_D, net_G, trainloader,\n",
    "      num_epochs, lr_D, lr_G,\n",
    "      latent_dim, data[:100].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "----------\n",
    "\n",
    "- Generative adversarial networks (GANs) composes of two deep networks, the generator and the discriminator.\n",
    "- The generator generates the image as much closer to the true image as possible to fool the discriminator, via maximizing the cross-entropy loss, i.e., $\\max \\log(D(\\mathbf{x'}))$.\n",
    "- The discriminator tries to distinguish the generated images from the true images, via minimizing the cross-entropy loss, i.e., $\\min - y \\log D(\\mathbf{x}) - (1-y)\\log(1-D(\\mathbf{x}))$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
